---
layout: post
title:  "추천시스템 공부 (1) - 전반적인 내용"
date:   2021-04-07
categories: ["2021","AI"]
update: 2021-04-07
tags: [AI,Recommendation]
---

추천 알고리즘을 입문하려고 하는 저에게 친구가 보면 좋다고 소개해준 글 + 추가로 찾아본 글을 정리해 보겠습니다.

### Intro 

![image](https://user-images.githubusercontent.com/51329156/100213332-d35ee480-2f51-11eb-9d0b-20b17ed189d8.png)

추천 시스템을 공부하는 배경에는, 세상은 연결되어 있다는 사실이 있습니다. 세상은 저희가 생각하는 것보다도 훨씬 더 밀접하게 연결되어 있습니다.  위 그림에서 확인할 수 있듯이 사용자와 사용자간의 연결이 있고, 사용자와 아이템간의 연결이 있습니다. `u1`과 `u2`는 sns 상 친구이고, 두 사용자는 둘다 i1(`Shape of You`)를 좋아합니다. 이 뿐만이 아니라 아이템과 아이템 사이에도 같은 가수, 같은 장르인지에 따라 연결이 만들어집니다. 

추천 시스템을 크게 나누자면 두 가지가 있습니다.

- **Content-based filtering** : 사용자나 아이템을 몇 가지 특징(이름, 제목, 장르, ..)으로 표현하고 같은 특징을 가진 다른 아이템을 추천하는 방식입니다. **Collaborative filtering**은 사용자와 아이템간의 상호작용을 분석하는 방법인 반면 이 방법은 아이템 자체끼리 비슷한지 비교하는 방법입니다. 아이템을 하나의 벡터로 표현한 다음, clustering 알고리즘을 통해 아이템을 여러 cluster로 나눕니다. 그리고 사용자가 선택한 아이템과 같은 cluster에 있는 다른 아이템을 추천하는 방식입니다. 이 방식은 과거에 사용자가 선택했던 아이템을 기반으로 추천해주기 때문에 한계가 많습니다.
- **Collaborative filtering** : 사용자와 아이템 간의 상호작용 정보를 통해 사용자가 좋아할 만한 아이템을 추천합니다. 기본적인 개념은 사용자-아이템 상호작용 정보를 통해 비슷한 사용자 or 비슷한 아이템들을 찾아내서 선호할 만한 아이템을 추천하는 방식입니다. **Content-based filtering**과는 다르게 사용자나 아이템 자체의 특성을 추천에 사용하지 않습니다. 이 글에서는 이 방법에 대해 주로 설명하겠습니다.

### Overview of Recommendation Engine

![image](https://user-images.githubusercontent.com/51329156/100213911-9515f500-2f52-11eb-8cb3-3dfe16edfec8.png)

**User interest**, 즉 사용자가 아이템에 매기는 점수는 별점을 주는 행위와 같이 직접적(Explicit)으로 드러날 수도 있지만, 간접적(Implicit)인 방법으로 나타나는 경우도 있습니다. 이 때까지 사용자가 남긴 좋아요들, 웹페이지에 머무른 시간 등은 직접적으로 드러나지는 않지만 사용자의 interest를 나타낼 수 있습니다. 여기서 말하는 아이템은 영화, 친구, 뉴스 등등이 될 수 있습니다. 

여기서 문제는, **User**와 **Item**간에 존재하는 차이를 어떻게 해결하느냐 입니다. 당연하게도 사용자와 아이템은 다른 타입의 개체이기 때문에 사용자는 사용자의 특성에 의해 표현되고, 아이템은 아이템의 특성에 맞게 표현될 것입니다. 이러한 차이가 있음에도 불구하고, 아이템에 대한 사용자의 **User interest**를 구하는 게 주 목적이라 보시면 됩니다.

이 내용과 위 그림을  공식화해봅시다. **Input**은 이 때까지 사용자가 아이템들과 해온 interaction의 기록들과 추가적인 정보들(사용자의 국적 등)이 될 수 있습니다. **Output**에는 사용자가 아이템을 얼마나 좋아할지 점수로 나타내고 점수가 높은 TOP-N 아이템이 올 수 있습니다. 혹은 사용자가 아직 평가하지 않은 아이템에 대해 어떻게 평가할지를 예측한 값이 올 수 있습니다. 예를 들어 준용이가 테넷을 얼마나 좋아하는지 예측할 때, **Input**으로는 이 때까지 사용자가 다른 아이템들에 매긴 별점을 넣고, **Output**에 준용이가 테넷에 매길 것 같은 별점을 내 놓는 것입니다. 

### 추천 시스템이 풀고자 하는 문제

 **랭킹 문제**

사용자가 아이템에 남길 평점(점수)를 정확하게 예측할 필요가 없습니다. 대신 특정 사용자가 좋아할만한 Top-N 아이템을 선정하거나, 특정 아이템을 좋아할만한 Top-N 사용자를 선정할 수 있습니다. 정확한 점수보다는 대상간의 순서가 중요한 문제입니다.

**예측 문제**

사용자-아이템 조합에서 평점(점수)를 정확히 예측하는 것을 목표로 합니다. 사용자-아이템 행렬을 채우는 문제로도 볼 수 있습니다. 사용자(m) x 아이템(n) 의 m X n 행렬에서 비어있는 부분이 존재할 때, 관측값(채워져있는 값)은 모델 학습에 사용하고, 결측값(비어있는 값)은 모델 평가에 사용합니다.

## 협업 필터링(Collaborative Filtering)

**협업 필터링**은 **User interest**를 예측할 때 많은 사용자들로부터 모은 취향 정보들을 이용해 예측하는 기술을 의미합니다. 예를 들어서 준용이와 승윤이의 영화취향이 비슷할 때, 승윤이가 테넷을 좋아할 것인가? 에 대해서는 **YES**라고 판단합니다. (예제는 위와 이어집니다). 즉 비슷한 사용자들은 아마도 비슷한 취향을 가지고 있을 것이라고 예측합니다. 

**협업 필터링**의 종류에는 Memory-based CF, Model-based CF, Hybrid가 있습니다. 

- **memory-based** : 데이터로 주어지는 사용자-아이템 상호작용 행렬을 그대로 다 활용해서 사용자의 rating을 예측하는 방법입니다.
- **model-based** : 사용자-아이템 상호작용 행렬을 통해 model을 학습시키고 이 모델을 가지고 rating을 예측하는 방법입니다. 

### Memory-based CF

![image](https://user-images.githubusercontent.com/51329156/100218541-381d3d80-2f58-11eb-8d71-438e9ed9112f.png)

위 그림에서 보면 u1는 i1에 대해 별점 5점을 남겼고, 다른 아이템들에 대해서는 별점을 남기지 않았습니다. 현실에서 실제로 사용자들이 모든 아이템에 별점을 남기지는 않습니다. 

여기서 저희가 해결해야 하는 문제가 빨간색 표시가 된 부분(u1의 i4에 대한 평가)을 예측하는 것이라고 해봅시다. **Memory-based CF**는 유사도를 기반하여 동작합니다. 이 때 말하는 유사도는 사용자와 사용자간의 유사도가 될 수도 있고, 아이템과 아이템간의 유사도가 될 수도 있습니다. 사용자 사이의 유사도를 기준으로 하는 경우는 **User-based**, 아이템 사이의 유사도를 기준으로 하는 경우는 **Item-based**이라고 합니다.

|      | 테넷 | 인터스텔라 | 겨울왕국 | 어바웃 타움 |
| ---- | ---- | ---------- | -------- | ----------- |
| 준용 | 5    | 4          | ?        | 2           |
| 승윤 | ?    | 4          | 1        | 5           |
| 동욱 | 1    | ?          | 5        | ?           |
| 서연 | ?    | ?          | 3        | 4           |
| 무열 | 5    | 3          | 3        | ?           |

**사용자 기반 (User-Based)**

사용자 기반에서는 한 사용자가 평가한 영화들의 평점들을 가지고 벡터로 표현합니다. 위의 표를 보면 준용의 평가 벡터는 `(5,4,-,2)`이고 승윤의 평가 벡터는 `(-,4,1,5)`입니다. 이 때 두 사용자간 유사도는 두 벡터 간 유사도로 정의합니다. 식으로 나타내면 다음과 같습니다 :

![image](https://user-images.githubusercontent.com/51329156/100496370-f62e0a80-3196-11eb-87d2-526179d9084d.png)

유사도를 구하는 방법에는 여러가지가 있지만 이번에는 간단한 코사인 유사도를 사용하겠습니다.

코사인 유사도를 이용해 사용자 간 유사도를 구할 때는 두 사용자가 공통으로 평가한 항목에 대해서만 계산합니다. 즉 준용과 승윤의 유사도를 계산할 때 `A=(4,2)`,`B=(4,5)`이고 코사인 유사도를 구해보면 다음과 같습니다 :

![image](https://user-images.githubusercontent.com/51329156/100496381-0cd46180-3197-11eb-89d2-c6153d8d7a0e.png)

이런 식으로 모든 사용자 간의 유사도를 구하면 사용자 수 * 사용자 수(5*5) 크기의 유사도 행렬을 만들 수 있습니다. 만약 동욱이 인터스텔라에 남긴 평점을 구하고 싶으면 유사한 몇명의 점수를 이용해 구하거나 전체를 대상으로 weight sum 값을  사용할 수 있습니다. 전자를 식으로 나타내면 다음과 같습니다 : 

![image](https://user-images.githubusercontent.com/51329156/100496388-165dc980-3197-11eb-9533-5ebc52746bad.png)

위의 수식은 유사한 사용자들을 구해 (그 사용자와의 유사도 * 그 사용자의 예측값)들의 합을 예측값으로 사용하는 것을 의미합니다. 후자의 경우인 전체를 대상으로 weight sum 값을 사용하는 경우의 수식은 다음과 같습니다 :

![image](https://user-images.githubusercontent.com/51329156/100496394-22e22200-3197-11eb-859d-3234d0c01b1d.png)

**아이템 기반 (item-Based)**

아이템 기반은  아이템에 대해 사용자들이 어떤 식으로 평가했는지를 바탕으로 유사도를 계산합니다.  위의 행렬을 참고해서 테넷과 인터스텔라의 유사도를 구해봅시다. 테넷과 인터스텔라 모두를 평가한 사용자는 준용, 무열이고 각각을 벡터로 나타내면 `(5,4)`,`(5,3)` 입니다 :

![image](https://user-images.githubusercontent.com/51329156/100496399-32616b00-3197-11eb-8d2b-bf6ee652b039.png)

테넷과 인터스텔라의 유사도는 0.99로 상당힌 높은 유사도 입니다. 즉 테넷을 좋아하는 사람은 인터스텔라를 좋아할 확률이 높고 그 반대도 마찬가지임을 의미합니다.

### Model-based CF

사용자-아이템 interaction 행렬을 통해 model을 학습시키는 방법입니다. 학습시키고 나면 추천할 때는 model만 있으면 됩니다. 때문에 **memory-based**에 비해 scalability와 추천속도가  뛰어납니다. 여기서는 Latent Factor Model의 일종인 Matrix Factorization을 살펴보겠습니다.

**Matrix Factorization(행렬 인수분해)**

바로 위에서 Matrix Factorization(MF)는 Latent Factor 모델의 일종이라고 했습니다. Latent Factor 모델이 하고 싶은 것은, 사용자와 아이템을 각각 20-100 차원 정도의 vector로 표현하는 것입니다. 이 벡터는 기존 데이터에서 나타나는 rating 정보를 이용해 학습합니다. 즉 원래 사용자-아이템 상호작용 행렬을 사용자, 아이템 각각의 행렬로 쪼개는데, 곱했을 때 상호작용 행렬이 잘 나타나지도록 각각의 vector를 학습시키는 것이 목표입니다. **content-based** 방법에서 아이템을 제목, 장르, 가수 등으로 표현했다면 latent factor 모델에서는 상호작용 행렬을 통해 학습된, 기계가 이해하는 특징들로 표현합니다. 때문에 **content-based**보다 훨씬 풍부한 정보를 표현할 수 있습니다.

사용자와 아이템을 각각 vector로 나타낸다고 했는데, 이 때 두 vector의 차원은 같게 만듭니다. 아래의 예제는 latent factor 모델을 단순화시킨 그림입니다. x축은 양의 방향으로 갈수록 남성임을 의미하고, y축은 양의 방향으로 갈수록 Serious한 정도가 높음을 의미합니다 : 

![](https://dnddnjs.github.io/assets/img/Untitled-87d5c1c7-f6ef-44a6-ab29-fde9a30d609d.png)

Latent factor 모델에서 사용자와 아이템의 latent factor가 각 차원마다 같은 의미를 가지고, 사용자와 아이템 latent factor 끼리 dot-product 값이 높으면 추천하는 방식입니다. 위 그림에서는 **Gus**에게 `Dumb and Dumber`를 추천하고 `The Color Purple`은 추천하지 않겠네요. 

Matrix Factorization을 식으로 나타낼 수 있습니다. 여기서 q는 item latent factor matrix 이고 p는 user latent factor matrix 입니다. 사용자 u의 아이템 i에 대한 rating을 식으로 나타내면 다음과 같습니다 : 

![image](https://user-images.githubusercontent.com/51329156/100550029-52d61600-32ba-11eb-81fa-16cd51b7636f.png)

그림으로 보면 이해가 쉽습니다. MF를 처음 설명할 때 언급한 내용인데, MF는 사용자-아이템 행렬을 user latent factor matrix와 item latent factor matrix로 쪼개는 것입니다. 그리고 쪼개진 q와 p(아래 그림에서는 U와 V)를 곱했을 때 원래 사용자-아이템 행렬을 잘 만들어내는 것이 MF 학습의 핵심입니다.

![](https://buildingrecommenders.files.wordpress.com/2015/11/matrix-factorisation.png?w=900)

MF의 objective function은 다음과 같이 정의할 수 있습니다. 목표는 원래 rating을 예측하는 것으로, loss는 MSE loss를 사용합니다. 아래 식에서 K는 rating이 알려진 사용자-아이템 쌍을 말합니다. 위 그림에서는 노란색 표시가 된 경우를 얘기합니다. 이 때 MSE loss만 최소가 되게 학습시키면 되겠다고 생각할 수 있지만, 그러면 overfitting이 발생하게 됩니다. 그래서 **L2 regularization**을 사용합니다. **L2 regularization**은 overfitting을 막기 위해 cost function에 가중치의 제곱을 더하면서 학습하는 방식입니다. 

![image](https://user-images.githubusercontent.com/51329156/100550370-edcfef80-32bc-11eb-90c5-6757f62afe85.png)

위 objective function을 최소화하는 p와 q를 찾는 것이 목적이고, 이를 위한 방법은 생략하도록 하겠습니다.

### Deep Learning Meets CF

**Methods of Representation Learning(표현 학습)**

 DNN이 높은 성능을 내는 배경에는 복잡한 데이터 공간을 선형 분류가 가능할 정도로 단순화해 표현하기 때문이라는 이론이 있습니다. **표현학습**은 특정 task를 수행하기에 좋은 표현을 만드는 것을 의미합니다. 아래 그림에서는 Matrix Factorization과 표현학습을 사용한 것을 설명하고 있습니다 :

![image](https://user-images.githubusercontent.com/51329156/101655831-684efb00-3a85-11eb-9dd3-4963d047d482.png)

유저 Row에 대해 DNN을 사용해 Representation을 얻고, 아이템 Column에 대해서도 마찬가지로 Representation을 얻습니다. 그리고 그 얻은 두 표현을 이용해 Score를 얻습니다. 이 값이 높으면 User i가 Item j를 좋아한다고 판단하는 것입니다. Representation을 얻는다는 게 별 다른 게 아닙니다. MNIST 이미지를 받아서 0~9 사이의 숫자 중 무엇인지 판별하는 문제를 풀 때 MNIST 이미지를 여러 Layer를 거쳐 10차원의  데이터로 표현합니다. 이 과정도 마찬가지로 **Representation Learning**이라고 할 수 있습니다. 


### Updating ... 

> Reference
>
> 🚀 [https://next-nus.github.io/slides/tuto-cikm2019-public.pdf](https://next-nus.github.io/slides/tuto-cikm2019-public.pdf)
>
> 🚀 [협업 필터링 추천 시스템 (Collaborative Filtering Recommendation System)](https://scvgoe.github.io/2017-02-01-%ED%98%91%EC%97%85-%ED%95%84%ED%84%B0%EB%A7%81-%EC%B6%94%EC%B2%9C-%EC%8B%9C%EC%8A%A4%ED%85%9C-(Collaborative-Filtering-Recommendation-System)/)
>
> 🚀 [추천 시스템 Basics](https://dnddnjs.github.io/recomm/2019/08/15/recommendation_system_basics/)
>
> 🚀 [https://datajobs.com/data-science-repo/Recommender-Systems-[Netflix].pdf](https://datajobs.com/data-science-repo/Recommender-Systems-[Netflix].pdf)
>
> 🚀 [Overview of Recommender Algorithms – Part 2](https://buildingrecommenders.wordpress.com/2015/11/18/overview-of-recommender-algorithms-part-2/)

 

